{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ollama Web Rag\n",
    "## Config Web Loader"
   ],
   "id": "cbd1f4ee58e0cf36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:10:12.890637Z",
     "start_time": "2024-11-26T16:10:12.886914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=\"python\"\n",
    "PGVECTOR_CONNECTION_STRING=\"postgresql://localhost:5432/rag\"\n",
    "USER_AGENT=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\"\n",
    "OPENAI_API_KEY=\"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\"\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n"
   ],
   "id": "819b314d1a689abf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Webpages",
   "id": "d6817ba31a28d1b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:10:31.720746Z",
     "start_time": "2024-11-26T16:10:17.058275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://www.kodamakoifarm.com/koi-vs-carp/\",\n",
    "    \"https://www.kodamakoifarm.com/japanese-temples-shrines-koi-pond-gardens/\",\n",
    "    \"https://www.kodamakoifarm.com/goldfish/\",\n",
    "    \"https://www.kodamakoifarm.com/koi-rehoming-koi-rescue-organizations/\",\n",
    "    \"https://www.kodamakoifarm.com/taro-kodama-journey-into-world-of-koi-mastery/\",\n",
    "    \"https://www.kodamakoifarm.com/koi-herpes-virus-khv-disease-guide/\",\n",
    "    \"https://www.kodamakoifarm.com/sanitizing-letters/\",\n",
    "    \"https://www.kodamakoifarm.com/request-koi-donation/\",\n",
    "    \"https://www.kodamakoifarm.com/maintaining-and-fixing-pond-issues/\",\n",
    "    \"https://www.lawnstarter.com/blog/landscaping/koi-pond-maintenance/\",\n",
    "    \"https://www.thesprucepets.com/koi-pond-guide-5115233\",\n",
    "    \"https://www.kodamakoifarm.com/new-look-same-great-koi/\",\n",
    "]\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n"
   ],
   "id": "54bb6a62b7e84ee2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split text into chunks",
   "id": "840fd682a7576271"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:11:44.026317Z",
     "start_time": "2024-11-26T16:11:44.017456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#todo findout what tiktoken is text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "chunks = text_splitter.split_documents(docs_list)\n",
    "print(f\"Text split into {len(chunks)} chunks\")"
   ],
   "id": "9a921dab0eba83b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 432 chunks\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vector Database",
   "id": "ec597fcb0fa912f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:12:03.262534Z",
     "start_time": "2024-11-26T16:11:52.515849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection_name = \"local-rag\"\n",
    "\n",
    "# chroma_db_openai = Chroma.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "#     collection_name=f\"{collection_name}-openai\"\n",
    "# )\n",
    "# \n",
    "# chroma_db_nomic = Chroma.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "#     collection_name= f\"{collection_name}-nomic\"\n",
    "# )\n",
    "\n",
    "pgvector_db_openai = PGVector.from_documents(\n",
    "    collection_name=f\"{collection_name}-openai\",\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "    use_jsonb=True\n",
    ")\n",
    "pgvector_db_nomic = PGVector.from_documents(\n",
    "    collection_name=f\"{collection_name}-nomic\",\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    use_jsonb=True\n",
    ")\n",
    "\n",
    "print(f\"Vector database created successfully\")"
   ],
   "id": "40cbf18410e78c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created successfully\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Chain",
   "id": "e22bca1a3cc07fd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:12:24.038876Z",
     "start_time": "2024-11-26T16:12:24.027491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_model = \"llama3.2:latest\"\n",
    "#local_model = \"granite3-dense:8b\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "\n",
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant.  Your task is to generate 2 \n",
    "    different versions of the give user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on user question, your\n",
    "    goal is to help users overcome some of the limitations of distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\"\n",
    ")\n",
    "# chroma_retriever_openai = MultiQueryRetriever.from_llm(\n",
    "#     chroma_db_openai.as_retriever(),\n",
    "#     llm,\n",
    "#     prompt=query_prompt\n",
    "# )\n",
    "pg_retriever_openai = MultiQueryRetriever.from_llm(\n",
    "    pgvector_db_openai.as_retriever(),\n",
    "    llm,\n",
    "    prompt=query_prompt\n",
    ")\n",
    "# chroma_retriever_nomic= MultiQueryRetriever.from_llm(\n",
    "#     chroma_db_nomic.as_retriever(),\n",
    "#     llm,\n",
    "#     prompt=query_prompt\n",
    "# )\n",
    "pg_retriever_nomic = MultiQueryRetriever.from_llm(\n",
    "    pgvector_db_nomic.as_retriever(),\n",
    "    llm,\n",
    "    prompt=query_prompt\n",
    ")"
   ],
   "id": "4839fcb68b110d1f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:12:46.436038Z",
     "start_time": "2024-11-26T16:12:46.433767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"Answer the question on on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ],
   "id": "2f7dc1b07d6545f2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:12:47.965076Z",
     "start_time": "2024-11-26T16:12:47.961497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# chroma_chain_openai = (\n",
    "#     {\"context\": chroma_retriever_openai, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "pg_chain_openai = (\n",
    "    {\"context\": pg_retriever_openai, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# chroma_chain_nomic = (\n",
    "#     {\"context\": chroma_retriever_nomic, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "pg_chain_nomic = (\n",
    "    {\"context\": pg_retriever_nomic, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "ad21018c0871185d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:13:06.560609Z",
     "start_time": "2024-11-26T16:13:06.557542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def chroma_chat_with_web_openai(question): \n",
    "#     \"\"\"\n",
    "#     Chat with the PDF using our chain\n",
    "#     \"\"\"\n",
    "#     return display(Markdown(chroma_chain_openai.invoke(question)))\n",
    "def pg_chat_with_web_openai(question): \n",
    "    \"\"\"\n",
    "    Chat with the PDF using our chain\n",
    "    \"\"\"\n",
    "    return display(Markdown(pg_chain_openai.invoke(question)))\n",
    "# def chroma_chat_with_web_nomic(question): \n",
    "#     \"\"\"\n",
    "#     Chat with the PDF using our chain\n",
    "#     \"\"\"\n",
    "#     return display(Markdown(chroma_chain_nomic.invoke(question)))\n",
    "def pg_chat_with_web_nomic(question): \n",
    "    \"\"\"\n",
    "    Chat with the PDF using our chain\n",
    "    \"\"\"\n",
    "    return display(Markdown(pg_chain_nomic.invoke(question)))\n"
   ],
   "id": "98daf10915e7b59d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:56:28.409907Z",
     "start_time": "2024-11-11T18:56:21.759457Z"
    }
   },
   "cell_type": "code",
   "source": "chroma_chat_with_web_openai(\"What is prompt engineering?\")",
   "id": "1a1841d72c67644",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "According to the provided documents, prompt engineering, also known as In-Context Prompting, refers to methods for communicating with LLMs (Large Language Models) to steer their behavior for desired outcomes without updating the model weights. It is an empirical science that requires heavy experimentation and heuristics, as the effect of prompt engineering methods can vary a lot among models."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:56:30.660193Z",
     "start_time": "2024-11-11T18:56:28.418752Z"
    }
   },
   "cell_type": "code",
   "source": "chroma_chat_with_web_nomic(\"What is prompt engineering?\")",
   "id": "968fbeed6dc155b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "According to the provided context, Prompt Engineering (also known as In-Context Prompting) refers to methods for communicating with LLMs to steer their behavior towards desired outcomes without updating the model weights. It is an empirical science that requires heavy experimentation and heuristics, and its effect can vary greatly among models."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:14:04.140048Z",
     "start_time": "2024-11-26T16:13:55.367599Z"
    }
   },
   "cell_type": "code",
   "source": "pg_chat_with_web_openai(\"What virus's can a Koi catch?\")",
   "id": "e7f6924c9d6103d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Based on the provided context, it appears that a Koi can catch Koi Herpes Virus (KHV). This is mentioned multiple times throughout the documents, specifically in relation to its symptoms, transmission patterns, and prevention measures."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:15:17.994731Z",
     "start_time": "2024-11-26T16:15:15.479469Z"
    }
   },
   "cell_type": "code",
   "source": "pg_chat_with_web_nomic(\"What are steps for preventing herpes or treating KHV?\")",
   "id": "a890c44e62073e40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "According to the provided context, the article outlines several steps for preventing and managing Koi Herpes Virus (KHV):\n\nPrevention:\n\n1. Regular testing: Test your koi regularly for signs of KHV infection.\n2. Biosecurity measures: Implement biosecurity measures to prevent the spread of KHV, such as maintaining optimal pond conditions.\n3. Contact local vet or koi dealer first: If you suspect KHV infection, contact your local vet or koi dealer for guidance and testing.\n\nTreatment:\n\n1. Quarantine: Isolate infected koi to prevent further transmission.\n2. Consult veterinarians: Seek professional advice from veterinarians experienced in treating KHV infections.\n\nIt is essential to note that the article emphasizes the importance of not jumping to conclusions about KHV infection without proper testing, as this can lead to unnecessary panic and overreaction."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
